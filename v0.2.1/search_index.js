var documenterSearchIndex = {"docs":
[{"location":"library/#Library","page":"Library","title":"Library","text":"","category":"section"},{"location":"library/#User-Friendly-Interfaces","page":"Library","title":"User Friendly Interfaces","text":"","category":"section"},{"location":"library/","page":"Library","title":"Library","text":"symeigs\nsvds","category":"page"},{"location":"library/#GenericArpack.symeigs","page":"Library","title":"GenericArpack.symeigs","text":"eigs(Symmetric(A), k; kwargs...)  # maps to symeigs \neigs(Hermitian(A), k; kwargs...)  # maps to hermeigs \nsymeigs(A, k; kwargs...)          # A must be symmetric, although we don't check. \nsymeigs(A, B, k; kwargs...)       # A must be sym, B must be sym. pos. def, not checked \nsymeigs(op, k; kwargs...)         # uses ArpackOp to handle multiple problem types \nhermeigs(A, k; kwargs...)         # forces complex valued vectors; A not checked.     \nhermeigs(A, B k; kwargs...)       # forces complex valued vectors; A not checked.     \nsymeigs(TV, TF, op, k; kwargs...) # the most general implmementation\n\nThese functions compute Symmetric and Hermitian Eigenspaces hence, symeigs for symmetric eigenspace.\n\nCalling sequence: the call is implemented with everything mapped to the single, most general call with symeigs. \n\nType parameters\n\nTV: The element type of the vector information; we need TV <: Complex for Hermitian problems\nTF: The element type of the factorization information; we need TV <: Real for  all problems. \n\nNote that it is okay to mix different precisions, although the lowest precision will  determine the default tolerance; e.g. TV = Float32, TF = Float64 will use a default tolerance from Float32. \n\nArguments\n\nSymmetric(A) or Hermitian(A) a matrix whose type indicates it is symmetric or Hermitian\nk::Integer the size of the eigenspace to compute. (i.e. the number of eigenvectors)\nA a square matrix that should be symmetric (but we won't check)\nB or Symmetric(B) or Hermitian(B) like A, but for a generalized eigenvalue problem.  The matrix B will be factorized via factorize(B), if you need more control, use ArpackSymmetricGeneralizedOp, or see one of the more advanced generalized interfaces below. \nop::ArpackOp An Arpack instance that holds the minimal information we need to run Arpack\n\nOptional arguments\n\nwhich: which part of the spectrum to compute. There are a few choices: \n:LM (the default) find the largest magnitude eigenspace \n:SM find the smallest magnitude eigenspace\n:LA find the largest algebraic value eigenspace \n:SA find the smallest algebraic value eigenspace     \n:BE find both smallest and largest algebraic eigenspace\nncv: the number of vectors used in the Arnoldi basis. The default value is min(2k, n)  where n is the dimension of the matrix. Increasing this value can help if there are  invariant subspaces with many nearby eigenvalues.\ntol: the tolerance on the error bound on the estimated eigenspace. The default value  is max(eps(TF), eps(TV))/2; if TV is a complex valued type, this means the underlying  element type. \nv0: a starting vector to build the initial basis. This should be of the same dimension  as the matrix itself. The default choice is to use a random vector by setting  v0=nothing. Note that  GenericArpack.jl includes it's own random number generator to  match the Fortran Arpack library. If you wish to match a sequence of calls, please  save the ArpackState information between subsequent calls. \nmaxiter:  the maximum number of restarted Arnoldi bases to build. Default value is 300.  this is highly conservative and may be changed in future \nfailonmaxiter: (default true) if the maximum number of iterations is hit and this is  true, then we force a hard error. Otherwise, we return information that can be used to run additional iterations. \nritzvec: This determines if we compute eigenvector information or not. If not, then the matrix of eigenvectors will have zero columns. \nstate: the ArpackState structure that stores information between calls. By default, we create a new state for each call. This stores information on the random number generator and information for the reverse communication interface.   \n\nOutput and results optional parameters\n\ndebug: This allow debugging output.  This must be an instance of ArpackDebug().  See the field information as well as the Arpack debugging information to understand what is logged. \nstats: This tracks timing statistics and the number of various operations performed; it must be an instance of ArpackStats(). \n\nAdvanced optional parameters\n\nmode: by default, the mode is set by the input or type of arpack op. While you can override this by setting it, this may result in incorrect behavior. In particular, we will throw a warning if the op seems inappropriate for the mode. The best way to use this is to use one of the more advanced ops, such as ArpackShiftInvertOp\nbmat: if bmat=Val(:I), then this is a standard eigenvalue problem. If bmat = Val(:G) then it is a generalized eigenvalue problem. By default, the choice of call and ArpackOp determines bmat and this should be changed rarely. \n\nSample calls\n\njulia> using LinearAlgebra, SparseArrays, GenericArpack\njulia> # standard real symmetric eigenvalue problem\njulia> n=100; symeigs(Tridiagonal(-ones(n-1),2*ones(n),-ones(n-1)).*(n+1), 5)\njulia> # real symmetric generalized eigenvalue problem\njulia> n=100; symeigs(Tridiagonal(-ones(n-1),2*ones(n),-ones(n-1)).*(n+1),\n                      SymTridiagonal(4*ones(n),ones(n-1))*(1/(6*(n+1))), 5)\njulia> # use Float32 type for information on smallest eigenvalue problem\njulia> n=100; symeigs(Float32, ArpackSimpleOp(Diagonal(1.0:n)), 5; which=:SA)\njulia> # complex Hermitian eigenvalue problem \njulia> n=100; symeigs(Tridiagonal(im*ones(n-1),2*ones(n).+0im,im*ones(n-1)).*(n+1), 5)\njulia> # mixed precision eigenvalue problem \njulia> n=100; symeigs(Float16, Float64, ArpackSimpleOp(Diagonal(1.0:n)), 5; which=:SA)\n\nSee also\n\nIf you wish more control over the interface and what is provided, your best solution is to work with the ArpackOp types, or write your own (it is very easy!)\n\nArpackSimpleFunctionOp: This wraps a general input to output function. \nArpackNormalOp: This is the op type used in the svds function \nArpackShiftInvertOp: This is your best way to use the Shift Inver\nArpackBucklingOp: \nsvds\n\n\n\n\n\n","category":"function"},{"location":"library/#GenericArpack.svds","page":"Library","title":"GenericArpack.svds","text":"svds(A, k; kwargs...)\nsvds(T::Type, A, k; kwargs...)\nsvds(TV::Type, TF::Type, A, k; kwargs...)\nsvds(TV::Type, TF::Type, op, k; kwargs...)\ncomplexsvds(op, k; kwargs...)\n\nTODO: Write documentation See examples... \n\n\n\n\n\n","category":"function"},{"location":"library/#ArpackOp-types","page":"Library","title":"ArpackOp types","text":"","category":"section"},{"location":"library/#User-facing-ArpackOp-types","page":"Library","title":"User-facing ArpackOp types","text":"","category":"section"},{"location":"library/","page":"Library","title":"Library","text":"ArpackSimpleOp\nArpackSimpleFunctionOp\nArpackSymmetricGeneralizedOp\n#ArpackSymmetricGeneralizedFunctionOp\nArpackNormalOp\nArpackNormalFunctionOp","category":"page"},{"location":"library/#GenericArpack.ArpackSimpleOp","page":"Library","title":"GenericArpack.ArpackSimpleOp","text":"ArpackSimpleOp(A)\n\nThis corresponds to a simple eigenvalue problem Ax = lambda x, and builds a Julia object that represents the minimal information Arpack needs about the matrix to run an eigenvalue problem. \n\nArguments\n\nA: Anything that implements Base.size, LinearAlgebra.mul!\n\nExamples\n\njulia> op = ArpackSimpleOp(A)\njuila> size(op) == size(A,1)\n\nSee also ArpackSymmetricGeneralizedOp, ArpackSimpleFunctionOp\n\n\n\n\n\n","category":"type"},{"location":"library/#GenericArpack.ArpackSimpleFunctionOp","page":"Library","title":"GenericArpack.ArpackSimpleFunctionOp","text":"ArpackSimpleFunctionOp(F::Function, n::Integer)\n\nThis corresponds to a simple eigenvalue problem Ax = lambda x, but  takes a functional operator that we apply.\n\nArguments\n\nF::Function this is a function (y,x) -> mul!(y,A,x), i.e. a function  that writes A*x into y\nn::Integer the dimension of the problem \n\nExamples\n\njulia> using GenericArpack, SparseArrays\njulia> function myf(y,x) \n       fill!(y, 0)\n       y[1] += x[2] + x[100]\n       for i in 2:99\n         y[i] += x[i+1] + x[i-1]\n       end\n       y[100] += x[99] + x[1]\n       end\njulia> op = ArpackSimpleFunctionOp(myf, 100)\n\n\n\n\n\n","category":"type"},{"location":"library/#GenericArpack.ArpackSymmetricGeneralizedOp","page":"Library","title":"GenericArpack.ArpackSymmetricGeneralizedOp","text":"ArpackSymmetricGeneralizedOp(A,invB,B)\n\nWe need three operations: Ax, invBx, B*x     B must also be symmetric, pos. def.  Note that if B can be factorized efficiently via Cholesky, then there is a better way to proceed. \n\nExamples\n\n```julia-repl julia> using GenericArpack, LinearAlgebra julia> n = 100  julia> A = Tridiagonal(-ones(n-1),2ones(n),-ones(n-1)).(n+1) julia> B = Tridiagonal(ones(n-1),4ones(n),ones(n-1)).(1/(6*(n+1))) julia> op = ArpackSymmetricGeneralizedOp(A, lu!(copy(B)), B)\n\nSee also ArpackSimpleOp\n\n\n\n\n\n","category":"type"},{"location":"library/#GenericArpack.ArpackNormalOp","page":"Library","title":"GenericArpack.ArpackNormalOp","text":"ArpackNormalOp(A)\n\nThis provides an ArpackSVDOp that is used as a bridge in svds  to call the symeigs routine. It maniuplates the so-called normal matrix  AA^H or A^H A depending on which  is smaller. Note that this function allocates memory to compute the operation, so it will not be safe to use with multiple threads. \n\nArguments\n\nA: Anything that implements Base.size, LinearAlgebra.mul!(y,A,x), LinearAlgebra.adjoint and LinearAlgebra.mul!(y,adjoint(A),x)`\n\nExamples\n\njulia> op = ArpackNormalOp(A)\n\nSee also ArpackNormalFunctionOp\n\n\n\n\n\n","category":"type"},{"location":"library/#GenericArpack.ArpackNormalFunctionOp","page":"Library","title":"GenericArpack.ArpackNormalFunctionOp","text":"ArpackNormalFunctionOp(ax::Function, atx::Function, m::Integer, n::Integer)\n\nArguments\n\nax A function to compute (y,x) and write y = A*x into the memory for y\natx A function to compute (y,x) and write y = A^H*x into the memory for y\nm the number of rows of A\nn the number of rows of A\n\nSee also ArpackNormalOp, ArpackSimpleFunctionOp\n\n\n\n\n\n","category":"type"},{"location":"library/#In-development-ArpackOp-types","page":"Library","title":"In-development ArpackOp types","text":"","category":"section"},{"location":"library/","page":"Library","title":"Library","text":"ArpackShiftInvertOp\nArpackBucklingOp","category":"page"},{"location":"library/#GenericArpack.ArpackShiftInvertOp","page":"Library","title":"GenericArpack.ArpackShiftInvertOp","text":"ArpackShiftInvertOp\n\nwarn: Do not use\nDo not use this operator yet. It was just some prototype code.    \n\n\n\n\n\n","category":"type"},{"location":"library/#GenericArpack.ArpackBucklingOp","page":"Library","title":"GenericArpack.ArpackBucklingOp","text":"ArpackBucklingOp\n\nc  Mode 4:  K*x = lambda*KG*x, K symmetric positive semi-definite,\nc           KG symmetric indefinite\nc           ===> OP = (inv[K - sigma*KG])*K  and  B = K.\nc           ===> Buckling mode\n\nwarn: Do not use\nDo not use this operator yet. It was just some prototype code.\n\n\n\n\n\n","category":"type"},{"location":"library/#Abstract-ArpackOp-Types","page":"Library","title":"Abstract ArpackOp Types","text":"","category":"section"},{"location":"library/","page":"Library","title":"Library","text":"ArpackOp","category":"page"},{"location":"library/#GenericArpack.ArpackOp","page":"Library","title":"GenericArpack.ArpackOp","text":"ArpackOp\n\nThe general abstract ArpackOp interface.     \n\nSee also ArpackSimpleOp,  ArpackSymmetricGeneralizedOp,  ArpackSimpleFunctionOp\n\n\n\n\n\n","category":"type"},{"location":"library/","page":"Library","title":"Library","text":"ArpackSVDOp","category":"page"},{"location":"library/#GenericArpack.ArpackSVDOp","page":"Library","title":"GenericArpack.ArpackSVDOp","text":"ArpackSVDSOp\n\nThe general abstract ArpackSVDOp interface that bridges between eigenvaules and singular values.\n\n\n\n\n\n","category":"type"},{"location":"library/#Helpers","page":"Library","title":"Helpers","text":"","category":"section"},{"location":"library/","page":"Library","title":"Library","text":"GenericArpack.svd_residuals","category":"page"},{"location":"library/#GenericArpack.svd_residuals","page":"Library","title":"GenericArpack.svd_residuals","text":"svd_residuals(A, U, s, V)\nsvd_residuals(A, SVD)\nsvd_residuals(A, U, s, V, k) # compute for only the top k \nsvd_residuals!(r, A, U, s, V) # write result in place\n\nCompute the residuals of an SVD computation A*Vi - Ui*sigmai, and return the result in a vector. \n\nUsing a matvec function\n\nNote that A can also be a function A(y,x), where y = A*x is updated  in place. e.g. svd(A,U,s,V) == svd((y,x)->mul!(y,A,x), U,s,V) are equivalent.\n\n\n\n\n\n","category":"function"},{"location":"library/#Arpack-drivers","page":"Library","title":"Arpack drivers","text":"","category":"section"},{"location":"library/","page":"Library","title":"Library","text":"GenericArpack.dsaupd!\nGenericArpack.simple_dseupd!","category":"page"},{"location":"library/#GenericArpack.dsaupd!","page":"Library","title":"GenericArpack.dsaupd!","text":"call dsaupd      ( IDO, BMAT, N, WHICH, NEV, TOL, RESID, NCV, V, LDV, IPARAM,        IPNTR, WORKD, WORKL, LWORKL, INFO )\n\nArguments\n\nIDO     Integer.  (INPUT/OUTPUT)          Reverse communication flag.  IDO must be zero on the first          call to dsaupd .  IDO will be set internally to          indicate the type of operation to be performed.  Control is          then given back to the calling routine which has the          responsibility to carry out the requested operation and call          dsaupd  with the result.  The operand is given in          WORKD(IPNTR(1)), the result must be put in WORKD(IPNTR(2)).          (If Mode = 2 see remark 5 below)          ––––––––––––––––––––––––––––––-          IDO =  0: first call to the reverse communication interface          IDO = -1: compute  Y = OP * X  where                    IPNTR(1) is the pointer into WORKD for X,                    IPNTR(2) is the pointer into WORKD for Y.                    This is for the initialization phase to force the                    starting vector into the range of OP.          IDO =  1: compute  Y = OP * X where                    IPNTR(1) is the pointer into WORKD for X,                    IPNTR(2) is the pointer into WORKD for Y.                    In mode 3,4 and 5, the vector B * X is already                    available in WORKD(ipntr(3)).  It does not                    need to be recomputed in forming OP * X.          IDO =  2: compute  Y = B * X  where                    IPNTR(1) is the pointer into WORKD for X,                    IPNTR(2) is the pointer into WORKD for Y.          IDO =  3: compute the IPARAM(8) shifts where                    IPNTR(11) is the pointer into WORKL for                    placing the shifts. See remark 6 below.          IDO = 99: done          ––––––––––––––––––––––––––––––-\n\nBMAT    Character1.  (INPUT)          BMAT specifies the type of the matrix B that defines the          semi-inner product for the operator OP.          B = 'I' -> standard eigenvalue problem Ax = lambdax          B = 'G' -> generalized eigenvalue problem Ax = lambdaBx\n\nN       Integer.  (INPUT)          Dimension of the eigenproblem.\n\nWHICH   Character*2.  (INPUT)          Specify which of the Ritz values of OP to compute.\n\n     'LA' - compute the NEV largest (algebraic) eigenvalues.\n     'SA' - compute the NEV smallest (algebraic) eigenvalues.\n     'LM' - compute the NEV largest (in magnitude) eigenvalues.\n     'SM' - compute the NEV smallest (in magnitude) eigenvalues.\n     'BE' - compute NEV eigenvalues, half from each end of the\n            spectrum.  When NEV is odd, compute one more from the\n            high end than from the low end.\n      (see remark 1 below)\n\nNEV     Integer.  (INPUT)          Number of eigenvalues of OP to be computed. 0 < NEV < N.\n\nTOL     Double precision  scalar.  (INPUT)          Stopping criterion: the relative accuracy of the Ritz value          is considered acceptable if BOUNDS(I) .LE. TOL*ABS(RITZ(I)).          If TOL .LE. 0. is passed a default is set:          DEFAULT = DLAMCH ('EPS')  (machine precision as computed                    by the LAPACK auxiliary subroutine DLAMCH ).\n\nRESID   Double precision  array of length N.  (INPUT/OUTPUT)          On INPUT:          If INFO .EQ. 0, a random initial residual vector is used.          If INFO .NE. 0, RESID contains the initial residual vector,                          possibly from a previous run.          On OUTPUT:          RESID contains the final residual vector.\n\nNCV     Integer.  (INPUT)          Number of columns of the matrix V (less than or equal to N).          This will indicate how many Lanczos vectors are generated          at each iteration.  After the startup phase in which NEV          Lanczos vectors are generated, the algorithm generates          NCV-NEV Lanczos vectors at each subsequent update iteration.          Most of the cost in generating each Lanczos vector is in the          matrix-vector product OP*x. (See remark 4 below).\n\nV       Double precision  N by NCV array.  (OUTPUT)          The NCV columns of V contain the Lanczos basis vectors.\n\nLDV     Integer.  (INPUT)          Leading dimension of V exactly as declared in the calling          program.\n\nIPARAM  Integer array of length 11.  (INPUT/OUTPUT)          IPARAM(1) = ISHIFT: method for selecting the implicit shifts.          The shifts selected at each iteration are used to restart          the Arnoldi iteration in an implicit fashion.          ––––––––––––––––––––––––––––––-          ISHIFT = 0: the shifts are provided by the user via                      reverse communication.  The NCV eigenvalues of                      the current tridiagonal matrix T are returned in                      the part of WORKL array corresponding to RITZ.                      See remark 6 below.          ISHIFT = 1: exact shifts with respect to the reduced                      tridiagonal matrix T.  This is equivalent to                      restarting the iteration with a starting vector                      that is a linear combination of Ritz vectors                      associated with the \"wanted\" Ritz values.          ––––––––––––––––––––––––––––––-\n\n     IPARAM(2) = LEVEC\n     No longer referenced. See remark 2 below.\n\n     IPARAM(3) = MXITER\n     On INPUT:  maximum number of Arnoldi update iterations allowed.\n     On OUTPUT: actual number of Arnoldi update iterations taken.\n\n     IPARAM(4) = NB: blocksize to be used in the recurrence.\n     The code currently works only for NB = 1.\n\n     IPARAM(5) = NCONV: number of \"converged\" Ritz values.\n     This represents the number of Ritz values that satisfy\n     the convergence criterion.\n\n     IPARAM(6) = IUPD\n     No longer referenced. Implicit restarting is ALWAYS used.\n\n     IPARAM(7) = MODE\n     On INPUT determines what type of eigenproblem is being solved.\n     Must be 1,2,3,4,5; See under Description of dsaupd  for the\n     five modes available.\n\n     IPARAM(8) = NP\n     When ido = 3 and the user provides shifts through reverse\n     communication (IPARAM(1)=0), dsaupd  returns NP, the number\n     of shifts the user is to provide. 0 < NP <=NCV-NEV. See Remark\n     6 below.\n\n     IPARAM(9) = NUMOP, IPARAM(10) = NUMOPB, IPARAM(11) = NUMREO,\n     OUTPUT: NUMOP  = total number of OP*x operations,\n             NUMOPB = total number of B*x operations if BMAT='G\",\n             NUMREO = total number of steps of re-orthogonalization.\n\nIPNTR   Integer array of length 11.  (OUTPUT)          Pointer to mark the starting locations in the WORKD and WORKL          arrays for matrices/vectors used by the Lanczos iteration.          ––––––––––––––––––––––––––––––-          IPNTR(1): pointer to the current operand vector X in WORKD.          IPNTR(2): pointer to the current result vector Y in WORKD.          IPNTR(3): pointer to the vector B * X in WORKD when used in                    the shift-and-invert mode.          IPNTR(4): pointer to the next available location in WORKL                    that is untouched by the program.          IPNTR(5): pointer to the NCV by 2 tridiagonal matrix T in WORKL.          IPNTR(6): pointer to the NCV RITZ values array in WORKL.          IPNTR(7): pointer to the Ritz estimates in array WORKL associated                    with the Ritz values located in RITZ in WORKL.          IPNTR(11): pointer to the NP shifts in WORKL. See Remark 6 below.\n\n     Note: IPNTR(8:10) is only referenced by dseupd . See Remark 2.\n     IPNTR(8): pointer to the NCV RITZ values of the original system.\n     IPNTR(9): pointer to the NCV corresponding error bounds.\n     IPNTR(10): pointer to the NCV by NCV matrix of eigenvectors\n                of the tridiagonal matrix T. Only referenced by\n                dseupd  if RVE= .TRUE. See Remarks.\n     -------------------------------------------------------------\n\nWORKD   Double precision  work array of length 3N.  (REVERSE COMMUNICATION)          Distributed array to be used in the basiArnoldi iteration          for reverse communication.  The user should not use WORKD          as temporary workspace during the iteration. Upon termination          WORKD(1:N) contains BRESID(1:N). If the Ritz vectors are desired          subroutine dseupd  uses this output.          See Data Distribution Note below.\n\nWORKL   Double precision  work array of length LWORKL.  (OUTPUT/WORKSPACE)          Private (replicated) array on each PE or array allocated on          the front end.  See Data Distribution Note below.\n\nLWORKL  Integer.  (INPUT)          LWORKL must be at least NCV**2 + 8*NCV .\n\nChanges:\n\nNote that info is only used for Input.  INFO    Integer.  (INPUT/OUTPUT)          If INFO .EQ. 0, a randomly initial residual vector is used.          If INFO .NE. 0, RESID contains the initial residual vector,                          possibly from a previous run.\n\nReturn value (this is info in Fortran)\n\nThe return value is a pair           Error flag on output.          =  0: Normal exit.          =  1: Maximum number of iterations taken.                All possible eigenvalues of OP has been found. IPARAM(5)                returns the number of wanted converged Ritz values.          =  2: No longer an informational error. Deprecated starting                with release 2 of ARPACK.          =  3: No shifts could be applied during a cycle of the                Implicitly restarted Arnoldi iteration. One possibility                is to increase the size of NCV relative to NEV.                See remark 4 below.          = -1: N must be positive.          = -2: NEV must be positive.          = -3: NCV must be greater than NEV and less than or equal to N.          = -4: The maximum number of Arnoldi update iterations allowed                must be greater than zero.          = -5: WHICH must be one of 'LM\", 'SM\", 'LA\", 'SA' or 'BE'.          = -6: BMAT must be one of 'I' or 'G'.          = -7: Length of private work array WORKL is not sufficient.          = -8: Error return from trid. eigenvalue calculation;                Informatinal error from LAPACK routine dsteqr .          = -9: Starting vector is zero.          = -10: IPARAM(7) must be 1,2,3,4,5.          = -11: IPARAM(7) = 1 and BMAT = 'G' are incompatible.          = -12: IPARAM(1) must be equal to 0 or 1.          = -13: NEV and WHICH = 'BE' are incompatible.          = -9999: Could not build an Arnoldi factorization.                   IPARAM(5) returns the size of the current Arnoldi                   factorization. The user is advised to check that                   enough workspace and array storage has been allocated.\n\n\n\n\n\n","category":"function"},{"location":"library/#GenericArpack.simple_dseupd!","page":"Library","title":"GenericArpack.simple_dseupd!","text":"Usage:   call dseupd        ( RVEC, HOWMNY, SELECT, D, Z, LDZ, SIGMA, BMAT, N, WHICH, NEV, TOL,        RESID, NCV, V, LDV, IPARAM, IPNTR, WORKD, WORKL, LWORKL, INFO )\n\nRVEC    LOGICAL  (INPUT)            Specifies whether Ritz vectors corresponding to the Ritz value            approximations to the eigenproblem Az = lambdaB*z are computed.\n\n         RVEC = .FALSE.     Compute Ritz values only.\n\n         RVEC = .TRUE.      Compute Ritz vectors.\n\nHOWMNY  Character*1  (INPUT)            Specifies how many Ritz vectors are wanted and the form of Z           the matrix of Ritz vectors. See remark 1 below.           = 'A': compute NEV Ritz vectors;           = 'S': compute some of the Ritz vectors, specified                  by the logical array SELECT.\n\nSELECT  Logical array of dimension NCV.  (INPUT/WORKSPACE)           If HOWMNY = 'S', SELECT specifies the Ritz vectors to be           computed. To select the Ritz vector corresponding to a           Ritz value D(j), SELECT(j) must be set to .TRUE..            If HOWMNY = 'A' , SELECT is used as a workspace for           reordering the Ritz values.\n\nD       Double precision  array of dimension NEV.  (OUTPUT)           On exit, D contains the Ritz value approximations to the           eigenvalues of Az = lambdaBz. The values are returned           in ascending order. If IPARAM(7) = 3,4,5 then D represents           the Ritz values of OP computed by dsaupd  transformed to           those of the original eigensystem Az = lambdaBz. If            IPARAM(7) = 1,2 then the Ritz values of OP are the same            as the those of Az = lambdaB*z.\n\nZ       Double precision  N by NEV array if HOWMNY = 'A'.  (OUTPUT)           On exit, Z contains the B-orthonormal Ritz vectors of the           eigensystem Az = lambdaB*z corresponding to the Ritz           value approximations.           If  RVEC = .FALSE. then Z is not referenced.           NOTE: The array Z may be set equal to first NEV columns of the            Arnoldi/Lanczos basis array V computed by DSAUPD .\n\nLDZ     Integer.  (INPUT)           The leading dimension of the array Z.  If Ritz vectors are           desired, then  LDZ .ge.  max( 1, N ).  In any case,  LDZ .ge. 1.\n\nSIGMA   Double precision   (INPUT)           If IPARAM(7) = 3,4,5 represents the shift. Not referenced if           IPARAM(7) = 1 or 2.\n\n**** The remaining arguments MUST be the same as for the   ****   **** call to DSAUPD  that was just completed.               ****\n\nNOTE: The remaining arguments\n\n       BMAT, N, WHICH, NEV, TOL, RESID, NCV, V, LDV, IPARAM, IPNTR,\n       WORKD, WORKL, LWORKL, INFO\n\n     must be passed directly to DSEUPD  following the last call\n     to DSAUPD .  These arguments MUST NOT BE MODIFIED between\n     the the last call to DSAUPD  and the call to DSEUPD .\n\nTwo of these parameters (WORKL, INFO) are also output parameters:\n\nWORKL   Double precision  work array of length LWORKL.  (OUTPUT/WORKSPACE)           WORKL(1:4ncv) contains information obtained in           dsaupd .  They are not changed by dseupd .           WORKL(4ncv+1:ncvncv+8ncv) holds the           untransformed Ritz values, the computed error estimates,           and the associated eigenvector matrix of H.\n\n      Note: IPNTR(8:10) contains the pointer into WORKL for addresses\n      of the above information computed by dseupd .\n      -------------------------------------------------------------\n      IPNTR(8): pointer to the NCV RITZ values of the original system.\n      IPNTR(9): pointer to the NCV corresponding error bounds.\n      IPNTR(10): pointer to the NCV by NCV matrix of eigenvectors\n                 of the tridiagonal matrix T. Only referenced by\n                 dseupd  if RVEC = .TRUE. See Remarks.\n      -------------------------------------------------------------\n\nINFO    Integer.  (OUTPUT)           Error flag on output.           =  0: Normal exit.           = -1: N must be positive.           = -2: NEV must be positive.           = -3: NCV must be greater than NEV and less than or equal to N.           = -5: WHICH must be one of 'LM', 'SM', 'LA', 'SA' or 'BE'.           = -6: BMAT must be one of 'I' or 'G'.           = -7: Length of private work WORKL array is not sufficient.           = -8: Error return from trid. eigenvalue calculation;                 Information error from LAPACK routine dsteqr .           = -9: Starting vector is zero.           = -10: IPARAM(7) must be 1,2,3,4,5.           = -11: IPARAM(7) = 1 and BMAT = 'G' are incompatible.           = -12: NEV and WHICH = 'BE' are incompatible.           = -14: DSAUPD  did not find any eigenvalues to sufficient                  accuracy.           = -15: HOWMNY must be one of 'A' or 'S' if RVEC = .true.           = -16: HOWMNY = 'S' not yet implemented           = -17: DSEUPD  got a different count of the number of converged                  Ritz values than DSAUPD  got.  This indicates the user                  probably made an error in passing data from DSAUPD  to                  DSEUPD  or that the data was modified before entering                   DSEUPD .\n\nNotes on Julia interface\n\nwe eliminate 'howmny' and 'select' as they aren't used in the Arpack code.                 \nJulia doesn't need ldz, so we remove that too... \n\n\n\n\n\n","category":"function"},{"location":"","page":"Home","title":"Home","text":"using GenericArpack, LinearAlgebra","category":"page"},{"location":"#GenericArpack.jl-Documentation","page":"Home","title":"GenericArpack.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This library is a julia translation of the Arpack library.  I strongly recommend browsing the documentation on the  functions in that library: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"dsaupd\ndseupd","category":"page"},{"location":"","page":"Home","title":"Home","text":"The major portion of the Julia code is a translation of these functions. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"However, we also provide our own user-friendly interface to these codes. This is inspired by the eigs and svds interface in the Julia wrappers Arpack.jl, however it has  a number of simplifications.","category":"page"},{"location":"#Eigenvalue,-eigenvectors,-standard,-generalized.","page":"Home","title":"Eigenvalue, eigenvectors, standard, generalized.","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The documentation needs to talk about matrices and eigenvectors, of course. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"A standard eigenvalue and eigenvector is a pair: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Ax = lambda x where x is not-zero and x = 1 by convention","category":"page"},{"location":"","page":"Home","title":"Home","text":"If Ais symmetic, then all of the lambda are real. Note that  the vector x is only determined up to sign, as well as rotation  if there are multliple linearly independent  eigenvectors with the same eigenvalue.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Likewise if A is Hermitian, then all of the lambda are still real whereas the vectors are complex-valued.  Also, the vectors x are only unique up to scaling by complex-value  of magnitude 1. (i.e. e^itheta for an angle theta). ","category":"page"},{"location":"","page":"Home","title":"Home","text":"A generalized eigenvalue and eigenvector is a pair: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Ax = lambda Bx where x is not-zero and Bx = 1 by convention.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The vectors are just as unique as in the other cases. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"There are many complexities with eigenvalues and subtleties in the defintion. Please see the ARPACK manual for exact detail on what we mean here as this is a translation of ARPACK. ","category":"page"},{"location":"#ARPACK-Notes-and-Key-Parameters","page":"Home","title":"ARPACK Notes and Key Parameters","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The three key parameters of the Arpack methods are:","category":"page"},{"location":"","page":"Home","title":"Home","text":"k\nwhich\nncv ","category":"page"},{"location":"","page":"Home","title":"Home","text":"The goal of Arpack is to compute a partial eigenspace of a matrix. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"The size of this eigenspace is the number of dimension k requested. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"In order to decide which eigenspace we are targeting, we need to tell it!  Arpack uses the natural variable: which in order to provide this information.","category":"page"},{"location":"","page":"Home","title":"Home","text":"which: which part of the spectrum to compute. There are a few choices: \n:LM (the default) find the largest magnitude eigenspace \n:SM find the smallest magnitude eigenspace\n:LA find the largest algebraic value eigenspace \n:SA find the smallest algebraic value eigenspace     \n:BE find both smallest and largest algebraic eigenspace","category":"page"},{"location":"","page":"Home","title":"Home","text":"It turns out that ARPACK uses a strategy based on looking for a larger eigenspace than only k vectors. The parameter ncv (number of compute vectors) determines this size. These parameters must satisfy k  ncv le =n (where n is the dimension of the matrix).","category":"page"},{"location":"","page":"Home","title":"Home","text":"tip: Convergence issues\nIf your eigenproblem isn't converging, it is often useful to increase ncv instead as well as increasing maxiter. This is because if the eigenspace you are trying to find is poorly separated, it's easier to find if you can find any separation of a larger eigenspace. ","category":"page"},{"location":"#Examples-of-real-symmetric,-complex-Hermitian,-and-singular-value-decomposition","page":"Home","title":"Examples of real symmetric, complex Hermitian, and singular value decomposition","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The best way to understand the library is just to see a variety of examples.","category":"page"},{"location":"","page":"Home","title":"Home","text":"info: There is more than one way ... \nThere is more than one way to do something in GenericArpack.jl. This is by design and there are various limits to the interfaces. Also, there exist multiple synonymous calls. This is make it easier for someone reading your code to understand what you meant, and often because there is a small hint about what a natural default type would be. For instance:  hermeigs causes us to use ComplexF64 as a default type, whereas symeigs will use Float64 instead. Of course, if you all symeigs and specify ComplexF64, it'll work. Likewise, if you call hermeigs  and specify Float64, but on the other hand, your readers will probably be annoyed by that confusion, so use sparingly. ","category":"page"},{"location":"#Find-the-largest-eigenvalues-of-a-real-symmetric-matrix.","page":"Home","title":"Find the largest eigenvalues of a real symmetric matrix.","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Let A be any type in Julia that implements Base.size and LineareAlgebra.mul!(y,A,x). For instance, A can be a SparseMatrixCSC, a Matrix, a Tridiagonal, a Diagonal Moreover, we assume that A is symmetric (and we won't check). This can be a common error.","category":"page"},{"location":"","page":"Home","title":"Home","text":"n = 100 \nA = Tridiagonal(-ones(n-1), 2*ones(n), -ones(n-1))\nsymeigs(A, 6)","category":"page"},{"location":"","page":"Home","title":"Home","text":"using GenericArpack, LinearAlgebra\nn = 100 \nA = Tridiagonal(-ones(n-1), 2*ones(n), -ones(n-1))","category":"page"},{"location":"","page":"Home","title":"Home","text":"We can also use any of the following equivalent calls","category":"page"},{"location":"","page":"Home","title":"Home","text":"eigs(Symmetric(A), 6)\nhermeigs(Symmetric(A), 6)","category":"page"},{"location":"#Finding-the-largest-eigenvalues-with-an-operator","page":"Home","title":"Finding the largest eigenvalues with an operator","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"All GenericArpack calls are mapped to a single computational interface with an ArpackOp type.","category":"page"},{"location":"","page":"Home","title":"Home","text":"op = ArpackSimpleOp(A);\n\nsymeigs(op, 6)","category":"page"},{"location":"","page":"Home","title":"Home","text":"note: On limits of eigs call\nIn the previous block, we can't use eigs and must use symeigs. That's because right now, we only have the symmetric eigensolvers ported. However, since the op type has no way to tell eigs that it should pick the symmetric or non-symmetric version, we need to tell it. So if you see MethodError: no method matching eigs(::ArpackSimpleOp{ ... })That means you just need to call symeigs instead!  This will probaby get fixed at some point. ","category":"page"},{"location":"#Complex-Hermitian","page":"Home","title":"Complex Hermitian","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We also extend Arpack's symmetric solvers with the ability to solve Hermitian problems.","category":"page"},{"location":"","page":"Home","title":"Home","text":"n = 100 \nA = Tridiagonal(-ones(n-1)*1im, 2*ones(n).+0im, ones(n-1)*1im)\nhermeigs(A, 6)","category":"page"},{"location":"#SVD-(Singular-Value-Decomposition)-via-the-Normal-Equations","page":"Home","title":"SVD (Singular Value Decomposition) via the Normal Equations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Gene Golub often railed against the use of the normal equations for SVD computations.  However, he would also use them when appropriate. For computing singular  values via ARPACK, the normal equations offer a few advantages. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"smallest singular values \nthey reduce computation as the dimension of the vectors is smaller","category":"page"},{"location":"","page":"Home","title":"Home","text":"The downside is that they also reduce maximum obtainable accuracy. So please consider using the high-precision types we enable in GenericArpack.jl, if accuracy is desired.","category":"page"},{"location":"","page":"Home","title":"Home","text":"(I need a better SVD example here, but alas.)","category":"page"},{"location":"","page":"Home","title":"Home","text":"using GenericArpack, SparseArrays, StableRNGs \nA = sprand(StableRNG(1), 200, 100, 5/200)\nsvds(A, 3)","category":"page"},{"location":"","page":"Home","title":"Home","text":"using GenericArpack, SparseArrays, StableRNGs, LinearAlgebra \nA = sprand(StableRNG(1), 200, 100, 5/200)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We can also find the smallest subspace ","category":"page"},{"location":"","page":"Home","title":"Home","text":"svds(A, 3; which=:SM) # smallest ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Or only the singular values (although this doesn't really save as much work as it might sound like) and use them to compute the matrix 2-norm. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"vals = svds(A, 4; which=:BE, ritzvec=false, ncv=12).S # both smallest and largest\n[vals[end]/vals[1] cond(Matrix(A))]","category":"page"},{"location":"","page":"Home","title":"Home","text":"So we can estimate the matrix 2-norm with some reasonable  accuracy (in a well-conditioned case). ","category":"page"},{"location":"#Complex-SVD-(Singular-Value-Decomposition)","page":"Home","title":"Complex SVD (Singular Value Decomposition)","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This operation is not in the pure ARPACK library.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using GenericArpack, SparseArrays, StableRNGs \nA = sprand(StableRNG(1), ComplexF64, 200, 100, 5/200)\nsvds(A, 3)","category":"page"},{"location":"#Real-and-Complex-SVD-via-an-ArpackNormalOp","page":"Home","title":"Real and Complex SVD via an ArpackNormalOp","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"All of the complex SVD calls for any Arpack matrix type are mapped to a single call with an ArpackNormalOp","category":"page"},{"location":"","page":"Home","title":"Home","text":"svds(ArpackNormalOp(Float64, A), 3; which=:SM) # smallest ","category":"page"},{"location":"#Examples-of-Generalized-Eigenvalue-Problems","page":"Home","title":"Examples of Generalized Eigenvalue Problems","text":"","category":"section"},{"location":"#Generalized-Eigenvalue-Example-(from-Arpack-dsdrv3-sample).","page":"Home","title":"Generalized Eigenvalue Example (from Arpack dsdrv3 sample).","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"n = 100\nA = Tridiagonal(-ones(n-1),2*ones(n),-ones(n-1)).*(n+1)\nB = SymTridiagonal(4*ones(n),ones(n-1)).*(1/(6*(n+1)))\nvals, vecs = eigs(Symmetric(A), Symmetric(B), 4)","category":"page"},{"location":"#Complex-Hermitian-Generalized-Eigenvalue-Example","page":"Home","title":"Complex Hermitian Generalized Eigenvalue Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Not here yet! Send me one if you have one! ","category":"page"},{"location":"#Shift-Invert-Example","page":"Home","title":"Shift-Invert Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Not here yet! Send me one if you have one! (Need to test and debug the Shift Invert mode driver.)","category":"page"},{"location":"#Buckling-Mode-Example","page":"Home","title":"Buckling Mode Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Not here yet! Send me one if you have one! (Need to test and debug the Buckling mode driver.)","category":"page"},{"location":"#Examples-with-high-precision-(or-low-precision)-types","page":"Home","title":"Examples with high-precision (or low-precision) types","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Both svds and symeigs/hermeigs take in a set of types.","category":"page"},{"location":"#With-just-one-type","page":"Home","title":"With just one type","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Consider our initial tridiagonal matrix A.  By default, we use a float-type based on the element-type of the input matrix A. But when the input includes a specific type, we use that: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"eigs(Float32, Symmetric(A), 6) # use Float32 for all computations","category":"page"},{"location":"","page":"Home","title":"Home","text":"If A has a different float type, then we may use that. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Af32 = Float32.(A) # make a Float32 copy\nsymeigs(Float32.(A), 6) # will switch default to Float32. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"But if you give an op, that has no natural type, so we default to Float64","category":"page"},{"location":"","page":"Home","title":"Home","text":"op = ArpackSimpleOp(Float32.(A))\nsymeigs(op, 6)","category":"page"},{"location":"","page":"Home","title":"Home","text":"(This is because an ArpackOp may wrap a variety of information and we don't need the type information.)","category":"page"},{"location":"","page":"Home","title":"Home","text":"op = ArpackSimpleOp(Float32.(A))\nsymeigs(Float32, op, 6)","category":"page"},{"location":"#With-two-types","page":"Home","title":"With two types","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In fact, the symeigs functions all take in two types: the type of the Eigeninformation (which must be be non-complex) and the type of the vector information (which can be complex).","category":"page"},{"location":"","page":"Home","title":"Home","text":"op = ArpackSimpleOp(Float16.(A))\nsymeigs(ComplexF64, Float32, op, 6)","category":"page"},{"location":"","page":"Home","title":"Home","text":"tip: These are correct\nThese eigenvectors are correct, even though they aren't real-valued. It's just that they are less unique in the complex plane compared to the real-plane. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"This allows us to use higher or lower-precision in the vector compared with the eigeninformation (which also is used to represent the  Arnoldi factorization). ","category":"page"},{"location":"","page":"Home","title":"Home","text":"This uses BigFloat for the Eigenvalue information and Float64 for the vectors. This will realistically limit you to Float64 accuracy but might handle some edge cases better. (And BigFloat should really be a different type, but this was handy to write as it's  built into Julia.)","category":"page"},{"location":"","page":"Home","title":"Home","text":"symeigs(Float64, BigFloat, A, 3; ncv=36)","category":"page"},{"location":"#Advanced-usage","page":"Home","title":"Advanced usage","text":"","category":"section"},{"location":"#Writing-your-own-ArpackOp","page":"Home","title":"Writing your own ArpackOp","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"It is \"easy\" (says the developer) to write your own ArpackOp type. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Here is the code to wrap a function F in an ArpackOp. This is the complete implementation of the ArpackFunctionOp","category":"page"},{"location":"","page":"Home","title":"Home","text":"struct ArpackSimpleFunctionOp <: ArpackOp\n  F::Function \n  n::Int\nend \narpack_mode(::ArpackSimpleFunctionOp) = 1\nBase.size(op::ArpackSimpleFunctionOp) = op.n\nbmat(::ArpackSimpleFunctionOp) = Val(:I)\nopx!(y,op::ArpackSimpleFunctionOp,x) = op.F(y,x)\nis_arpack_mode_valid_for_op(mode::Int, ::ArpackSimpleFunctionOp) = mode == 1 ","category":"page"},{"location":"#The-Arpack-Drivers","page":"Home","title":"The Arpack Drivers","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"All of the Arpack interface is through the functions dsaupd and dseupd. (Yes, Lapack-heads, I know that it should be `saupd/seupd` in proper nomenclature, but I'll get around to fixing that at some point.)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The key differences from the standard interface are four new types of arguments for Julia. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"ArpackDebug controls the Arpack debug messages (from debug.h)\nArpackStats controls the Arpack statistics collected (from stats.h)\nidonow is the Julia information for avoiding the reverse communication  interface. It's slightly faster. But likely to make compile times  longer. I'm leaving it in even though it'll be a source of bugs, ugh. \nArpackState tracks the computation specific state that was in the Fortran save variables. This includes things like the random number seeds. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"For stats if the type is nothing, then we don't track stats.  Likewise for debug. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"The other key difference is that all of the functions return the info  value instead of setting the info parameter. (I didn't want a needed Ref type hanging around in the Julia code.)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Here is how a dsaupd call maps between the two libraries. This is one we use in the test code. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"ido = Ref{Int}(0); bmat=:I; which=:LM; \nstate = ArpackState{Float64}() # (or whatever the Eigenvector info is...)\nstats = nothing # okay to not track...\nierr, state = GenericArpack.dsaupd!(ido, Val(bmat), n, which, nev, tol, resid, ncv, V, ldv, iparam,\n  ipntr, workd, workl, lworkl, info_initv;\n  state, stats, debug # these are the new parameters, which are Julia keywoard params, so any order is okay! \n)\narierr = arpack_dsaupd!(arido, bmat, n, which, nev, tol, arresid, ncv, arV, ldv, ariparam, \n  aripntr, arworkd, arworkl, lworkl, info_initv)","category":"page"},{"location":"","page":"Home","title":"Home","text":"If tol=0, the tol parameter is typically initalized by Arpack to dlamch(\"E\") which is eps(Float64)/2. This parameter is then propagated to future calls since everything in Fortran is pass-by-reference. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Instead of worrying about this, we just set tol on each call to GenericArpack.dsaupd!; however this can cause some small issues if you try and compare our calls directly. So in those cases,  I recommend setting tol to be anything non-zero so Arpack won't touch it. ","category":"page"},{"location":"#Getting-debug-information","page":"Home","title":"Getting debug information","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can also pass ArpackStats and ArpackDebug to any of the higher-level drivers.","category":"page"},{"location":"","page":"Home","title":"Home","text":"eigs(Symmetric(A), 3; debug=ArpackDebug(maupd=2, maup2=1), stats=ArpackStats()) # lots of convergence info","category":"page"}]
}
